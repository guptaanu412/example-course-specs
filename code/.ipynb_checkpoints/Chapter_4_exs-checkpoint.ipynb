{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: Preprocessing and pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Dropping Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using voting dataset, drop missing values with pandas'\n",
    ".`dropna()`.\n",
    "\n",
    "Note: Missing values are denoted by '?'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/house-votes-84.csv',\n",
    "                header=None, names = ['infants', 'water', 'budget', 'physician', 'salvador', 'religious',\n",
    "                                     'satellite', 'aid', 'missile', 'immigration', 'synfuels', 'education',\n",
    "                                     'superfund', 'crime', 'duty_free_exports', 'eaa_rsa'])\n",
    "\n",
    "df = df.reset_index()\n",
    "df.rename(columns = {'index': 'party'}, inplace = True)\n",
    "\n",
    "df[df == 'y'] = 1\n",
    "df[df == 'n'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "party                  0\n",
       "infants               12\n",
       "water                 48\n",
       "budget                11\n",
       "physician             11\n",
       "salvador              15\n",
       "religious             11\n",
       "satellite             14\n",
       "aid                   15\n",
       "missile               22\n",
       "immigration            7\n",
       "synfuels              21\n",
       "education             31\n",
       "superfund             25\n",
       "crime                 17\n",
       "duty_free_exports     28\n",
       "eaa_rsa              104\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many values to impute?\n",
    "df[df=='?'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Original DataFrame: (435, 17)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Original DataFrame: \" + str(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "party                  0\n",
       "infants               12\n",
       "water                 48\n",
       "budget                11\n",
       "physician             11\n",
       "salvador              15\n",
       "religious             11\n",
       "satellite             14\n",
       "aid                   15\n",
       "missile               22\n",
       "immigration            7\n",
       "synfuels              21\n",
       "education             31\n",
       "superfund             25\n",
       "crime                 17\n",
       "duty_free_exports     28\n",
       "eaa_rsa              104\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert '?' to NaN\n",
    "df[df == '?'] = np.nan\n",
    "df2 = df.copy(deep=True)\n",
    "\n",
    "#Demonstrate how to count NaNs w/ isnull()\n",
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame After Dropping All Rows with Missing Values: (232, 17)\n"
     ]
    }
   ],
   "source": [
    "df2 = df2.dropna()\n",
    "print(\"Shape of DataFrame After Dropping All Rows with Missing Values: \" + str(df2.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Imputing missing data in a ML pipeline I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute the missing values in the voting dataset with the most frequent value in each column.\n",
    "\n",
    "This is step 1 of building your first ML pipeline.\n",
    "\n",
    "Note: I chose not to go the .fillna() route here and instead introduce pipelines earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy='most_frequent', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Imputing missing data in a ML pipeline II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use sklearn's Imputer inside a pipeline to build a SVM classifier on\n",
    "the voting dataset. Use Pipeline() from sklearn.pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.969465648855\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   democrat       0.99      0.96      0.98        85\n",
      " republican       0.94      0.98      0.96        46\n",
      "\n",
      "avg / total       0.97      0.97      0.97       131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df = pd.read_csv('../datasets/house-votes-84.csv',\n",
    "                header=None, names = ['infants', 'water', 'budget', 'physician', 'salvador', 'religious',\n",
    "                                     'satellite', 'aid', 'missile', 'immigration', 'synfuels', 'education',\n",
    "                                     'superfund', 'crime', 'duty_free_exports', 'eaa_rsa'])\n",
    "\n",
    "df = df.reset_index()\n",
    "df.rename(columns = {'index': 'party'}, inplace = True)\n",
    "\n",
    "df[df == 'y'] = 1\n",
    "df[df == 'n'] = 0\n",
    "df[df == '?'] = np.nan\n",
    "\n",
    "# Create arrays for the features and the response variable. As a reminder, the response variable is 'party'\n",
    "y = df['party']\n",
    "X = df.drop('party', axis=1)\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy='most_frequent', axis=0)\n",
    "clf = svm.SVC()\n",
    "\n",
    "steps = [('imputation', imp),\n",
    "        ('SVM', clf)]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_test, y_pred)))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Centering and Scaling I: StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the features of Wine Quality Dataset with StandardScaler, then\n",
    "fit a K-NN classifier and compute accuracy. Compare against unscaled\n",
    "version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('../datasets/winequality-red.csv' , sep = ';')\n",
    "X = df.drop('quality' , 1).values # drop target variable\n",
    "y1 = df['quality'].values\n",
    "y = y1 <= 5\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6125\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.66      0.64      0.65       179\n",
      "       True       0.56      0.57      0.57       141\n",
      "\n",
      "avg / total       0.61      0.61      0.61       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "#Practice train/test split, fit, predict w/o scaling\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn_model_1 = knn.fit(X_train, y_train)\n",
    "\n",
    "y_true, y_pred = y_test, knn_model_1.predict(X_test)\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using StandardScaler() and k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.70625\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.72      0.78      0.75       179\n",
      "       True       0.69      0.62      0.65       141\n",
      "\n",
      "avg / total       0.70      0.71      0.70       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/winequality-red.csv' , sep = ';')\n",
    "X = df.drop('quality' , 1).values # drop target variable\n",
    "y1 = df['quality'].values\n",
    "y = y1 <= 5\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn_wine_std = knn.fit(X_train_std, y_train)\n",
    "\n",
    "y_true, y_pred = y_test, knn_wine_std.predict(X_test_std)\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7: Centering and Scaling II: RobustScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the features of Wine Quality Dataset with RobustScaler, then fit\n",
    "a logistic regression and compute accuracy. Compare against unscaled\n",
    "version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Without Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.740625\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.78      0.74      0.76       179\n",
      "       True       0.69      0.74      0.71       141\n",
      "\n",
      "avg / total       0.74      0.74      0.74       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "df = pd.read_csv('../datasets/winequality-red.csv' , sep = ';')\n",
    "X = df.drop('quality' , 1).values # drop target variable\n",
    "y1 = df['quality'].values\n",
    "y = y1 <= 5\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "lr = linear_model.LogisticRegression()\n",
    "# Fit the model\n",
    "lr = lr.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, lr.predict(X_test)\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using RobustScaler() and Logistic Regression (No Impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74375\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.79      0.74      0.76       179\n",
      "       True       0.70      0.74      0.72       141\n",
      "\n",
      "avg / total       0.75      0.74      0.74       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "df = pd.read_csv('../datasets/winequality-red.csv' , sep = ';')\n",
    "X = df.drop('quality' , 1).values # drop target variable\n",
    "y1 = df['quality'].values\n",
    "y = y1 <= 5\n",
    "\n",
    "Xs = RobustScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = RobustScaler().fit(X_train)\n",
    "Xs_train = scaler.transform(X_train)\n",
    "Xs_test = scaler.transform(X_test)\n",
    "\n",
    "lr = linear_model.LogisticRegression()\n",
    "lr_2 = lr.fit(Xs_train, y_train)\n",
    "y_true, y_pred = y_test, lr_2.predict(Xs_test)\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8: Centering and Scaling in a Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a pipeline to both normalize the data and fit a k-NN classifier to\n",
    "the Wine Quality dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.725\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.74      0.78      0.76       267\n",
      "       True       0.71      0.65      0.68       213\n",
      "\n",
      "avg / total       0.72      0.72      0.72       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/winequality-red.csv' , sep = ';')\n",
    "X = df.drop('quality' , 1).values # drop target variable\n",
    "y1 = df['quality'].values\n",
    "y = y1 <= 5\n",
    "\n",
    "scaler = Imputer(missing_values='NaN', strategy='most_frequent', axis=0)\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "steps = [('scaler', StandardScaler()),\n",
    "        ('knn', knn)]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_test, y_pred)))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 10: Dimensionality Reduction with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the features of the Wine Quality Dataset and then apply PCA. How\n",
    "many components to retain? Use PCA from sklearn.decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.28173931  0.1750827   0.1409585   0.11029387  0.08720837  0.05996439\n",
      "  0.05307193  0.03845061  0.0313311   0.01648483  0.00541439]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEQCAYAAABbfbiFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115a3e9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/winequality-red.csv' , sep = ';')\n",
    "X = df.drop('quality' , 1).values # drop target variable\n",
    "y1 = df['quality'].values\n",
    "y = y1 <= 5\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(X)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(Xs)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "plt.plot(pca.explained_variance_, linewidth=2)\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('explained_variance_')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 11: Effect of Dimensionality Reduction on Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a classifier to the Wine Quality Dataset after reducing\n",
    "dimensionality. Compare performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.671875\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.70      0.73      0.71       179\n",
      "       True       0.63      0.60      0.62       141\n",
      "\n",
      "avg / total       0.67      0.67      0.67       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Let's use 5 components\n",
    "\n",
    "reduced_wine = PCA(n_components=5).fit_transform(Xs)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(reduced_wine, y, test_size=0.2, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn_pca = knn.fit(X_train, y_train)\n",
    "\n",
    "y_true, y_pred = y_test, knn_pca.predict(X_test)\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 12: Putting it all together I: Pipeline for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a pipeline that includes scaling, PCA, and hyperparameter tuning\n",
    "on the Wine Quality Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73125\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.77      0.73      0.75       176\n",
      "       True       0.69      0.74      0.71       144\n",
      "\n",
      "avg / total       0.73      0.73      0.73       320\n",
      "\n",
      "Tuned Model Parameters: {'pca__n_components': 5, 'svm__C': 1000, 'svm__gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "df = pd.read_csv('../datasets/winequality-red.csv' , sep = ';')\n",
    "X = df.drop('quality' , 1).values # drop target variable\n",
    "y1 = df['quality'].values\n",
    "y = y1 <= 5\n",
    "\n",
    "pca = PCA()\n",
    "\n",
    "clf = svm.SVC()\n",
    "\n",
    "steps = [('scaler', StandardScaler()),\n",
    "         ('pca', pca),\n",
    "         ('svm', clf)]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "\n",
    "parameters = dict(pca__n_components=[1, 3, 5, 7], \n",
    "                  svm__C=[1, 10, 100, 1000],\n",
    "                  svm__gamma=[0.01, 0.001, 0.0001])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "y_pred = cv.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_test, y_pred)))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Tuned Model Parameters: \" + str(cv.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 13: Putting it all together II: Pipeline for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a pipeline that fits an ElasticNet and\n",
    "tunes the alpha using GridSearchCV on the Gapminder dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Need to rethink this exercise. Is a pipeline really needed here?\n",
    "# ElasticNetCV is a better alternative to GridSearchCV"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
